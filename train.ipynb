{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gymnasium==0.28.1\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Rainbow\n",
    "\n",
    "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
    "\n",
    "We will integrate all the following seven components into a single integrated agent, which is called Rainbow!\n",
    "\n",
    "1. DQN\n",
    "2. Double DQN\n",
    "3. Prioritized Experience Replay\n",
    "4. Dueling Network\n",
    "5. Noisy Network\n",
    "6. Categorical DQN\n",
    "7. N-step Learning\n",
    "\n",
    "This method shows an impressive performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. \n",
    "\n",
    "![rainbow](https://user-images.githubusercontent.com/14961526/60591412-61748100-9dd9-11e9-84fb-076c7a61fbab.png)\n",
    "\n",
    "However, the integration is not so simple because some of components are not independent each other, so we will look into a number of points that people especailly feel confused.\n",
    "\n",
    "1. Noisy Network <-> Dueling Network\n",
    "2. Dueling Network <-> Categorical DQN\n",
    "3. Categorical DQN <-> Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "# download segment tree module\n",
    "# if IN_COLAB:\n",
    "#     !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
    "import pickle\n",
    "from Agent.segment_tree import MinSegmentTree, SumSegmentTree\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ece/anaconda3/bin/project-RL304/project-RL304/')\n",
    "# sys.path.append('/content/project-RL304/Agent')\n",
    "\n",
    "from Agent.env import CustomEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Same as the basic N-step buffer. \n",
    "\n",
    "(Please see *01.dqn.ipynb*, *07.n_step_learning.ipynb* for detailed description about the basic (n-step) replay buffer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: Tuple[int], \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        self.obs_buf = np.zeros([size, *obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, *obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=idxs,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay Buffer\n",
    "\n",
    "`store` method returns boolean in order to inform if a N-step transition has been generated.\n",
    "\n",
    "(Please see *02.per.ipynb* for detailed description about PER.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6,\n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        if transition:\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        \n",
    "        return transition\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "Please see *05.noisy_net.ipynb* for detailed description.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        std_init: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.randn(size)\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoisyNet + DuelingNet + Categorical DQN\n",
    "\n",
    "#### NoisyNet + DuelingNet\n",
    "\n",
    "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
    "\n",
    "#### DuelingNet + Categorical DQN\n",
    "\n",
    "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
    "\n",
    "```\n",
    "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "```\n",
    "\n",
    "(Please see *04.dueling.ipynb*, *05.noisy_net.ipynb*, *06.categorical_dqn.ipynb* for detailed description of each component's network architecture.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "\n",
    "        # set common feature layer\n",
    "        self.Convolution_1 = nn.Sequential(           \n",
    "            nn.Conv1d(in_channels=33, out_channels=512, kernel_size=6, padding=1),  # Maintain spatial dimensions\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv1d(512, 1024, kernel_size=6, padding=1),  # Maintain spatial dimensions\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv1d(1024, 1536, kernel_size=6, padding=1),  # Maintain spatial dimensions\n",
    "            nn.BatchNorm1d(1536),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv1d(1536, 2048, kernel_size=5, padding=1),  # Maintain spatial dimensions\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv1d(2048, 2560, kernel_size=5, padding=1),  # Maintain spatial dimensions\n",
    "            nn.BatchNorm1d(2560),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv1d(2560, 3072, kernel_size=5, padding=1),  # Maintain spatial dimensions\n",
    "            nn.BatchNorm1d(3072),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # nn.Conv1d(3072, 3584, kernel_size=3, padding=1),  # Maintain spatial dimensions\n",
    "            # nn.BatchNorm1d(3584),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.2),\n",
    "            \n",
    "            # nn.Conv1d(3584, 4096, kernel_size=3, padding=1),  # Maintain spatial dimensions\n",
    "            # nn.BatchNorm1d(4096),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.2),\n",
    "            # nn.MaxPool1d(kernel_size=2),\n",
    "            # nn.Dropout(0.2),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten(1, 2)\n",
    "        # linear layers\n",
    "        self.Linear_layers = nn.Sequential(\n",
    "            # nn.Flatten(1, 2),\n",
    "            \n",
    "            nn.Linear(3072, 512),  # Adjusted input size\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
    "\n",
    "        # set value layer\n",
    "        self.value_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.value_layer = NoisyLinear(128, atom_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        x = x.permute(0, 2, 1)\n",
    "        Conv_1 = self.Convolution_1(x) # [batch_size, 42, 128]\n",
    "        linear = self.flatten(Conv_1)\n",
    "        linear = self.Linear_layers(linear)\n",
    "        # feature = torch.sum(feature, dim=1, keepdim=False) # [batch_size, 128]\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(linear))\n",
    "        val_hid = F.relu(self.value_hidden_layer(linear))\n",
    "        \n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()\n",
    "        self.advantage_layer.reset_noise()\n",
    "        self.value_hidden_layer.reset_noise()\n",
    "        self.value_layer.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(1, 3, 51, torch.tensor([i for i in range(-20, 21)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "conv_output = model.Convolution_1(torch.rand(1, 33, 42).cuda())\n",
    "flattened_output = model.flatten(conv_output)\n",
    "model.Linear_layers(flattened_output).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "#### Categorical DQN + Double DQN\n",
    "\n",
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
    "\n",
    "```\n",
    "        # Categorical DQN + Double DQN\n",
    "        # target_dqn is used when we don't employ double DQN\n",
    "        next_action = self.dqn(next_state).argmax(1)\n",
    "        next_dist = self.dqn_target.dist(next_state)\n",
    "        next_dist = next_dist[range(self.batch_size), next_action]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        seed: int,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 1,\n",
    "        model_path: str = None,\n",
    "        lr: int = 0.001\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.seed = seed\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # ploting data\n",
    "        self.episode = 0\n",
    "        self.inventory = []\n",
    "        self.portfolio = []\n",
    "        self.losses = []\n",
    "        self.scores = []\n",
    "\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # memory for 1-step Learning\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha, gamma=gamma\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "            \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(\n",
    "            obs_dim[1], action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "\n",
    "        if model_path != None:\n",
    "            self.dqn.load_state_dict(torch.load(model_path)['dqn_state_dict'])\n",
    "\n",
    "\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim[1], action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters(),lr=lr)\n",
    "        self.scheduler = ExponentialLR(self.optimizer, gamma=0.9999999)\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def Hyper_param(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        target_update: int,\n",
    "        seed: int,\n",
    "        gamma: float = 0.9999999,\n",
    "        model_path: str = None,\n",
    "        lr: int = 0.001\n",
    "    ):\n",
    "        obs_dim = env.observation_space.shape\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.target_update = target_update\n",
    "        self.seed = seed\n",
    "        \n",
    "        # Reinitialize the optimizer with the new learning rate\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters(), lr=lr)\n",
    "        \n",
    "        # Initialize the ExponentialLR scheduler with the new gamma\n",
    "        self.scheduler = ExponentialLR(self.optimizer, gamma=gamma)\n",
    "        \n",
    "        # Update the scheduler to apply the changes immediately\n",
    "        self.scheduler.step()\n",
    "\n",
    "        # Other initialization code...\n",
    "\n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        ).argmax()\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        if self.is_test:\n",
    "            self.dqn.reset_noise()\n",
    "            self.dqn_target.reset_noise()\n",
    "\n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, terminated, portfolio, item = self.env.step(action)\n",
    "        \n",
    "        self.portfolio.append(portfolio)\n",
    "        if len(item) != 0:\n",
    "                self.inventory.append(item[0])\n",
    "        elif len(self.inventory) != 0:\n",
    "                self.inventory.append(self.inventory[-1])\n",
    "        else:\n",
    "                self.inventory.append(0)\n",
    "        \n",
    "        \n",
    "        done = terminated\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "        \n",
    "        # 1-step Learning loss\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # PER: importance sampling before average\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            elementwise_loss += elementwise_loss_n_loss\n",
    "            \n",
    "            # PER: importance sampling before average\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "\n",
    "        state = self.env.reset(seed = self.seed)\n",
    "        update_cnt = 0\n",
    "        score = 0\n",
    "        # step = 0\n",
    "        # while True:\n",
    "        train_progress = tqdm(range(14258), desc=\"Training\", position=0, leave=True)\n",
    "        for step in train_progress:\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            self.scores.append(score*100)\n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(step / 14258, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "            \n",
    "            # plotting\n",
    "            if (step+1) % 200 ==0 and (step+1) % 1000 !=0 :\n",
    "                self._plot(self.episode,n_score = 150, n_portfolio=14258)\n",
    "            if (step+1) % 1000 == 0:\n",
    "                self._plot_all()\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset(seed = self.seed)\n",
    "                score = 0\n",
    "                self.episode += 1\n",
    "                break\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                train_progress.set_postfix({\"loss\": loss,\"Portfolio\":self.portfolio[-1],\"Inventory\":self.inventory[-1]})\n",
    "                self.losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "                    self.scheduler.step()\n",
    "\n",
    "\n",
    "    def save_model(self, directory=\"/home/ece/anaconda3/bin/project-RL304/project-RL304/Models\",filename = \"\",memory_fn=\"\"):\n",
    "        \"\"\"Save the model parameters to a file.\"\"\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        torch.save({\n",
    "            'dqn_state_dict': self.dqn.state_dict(),\n",
    "            'dqn_target_dict': self.dqn_target.state_dict(),\n",
    "        }, filepath)       \n",
    "        with open(\"MEMORY_\"+memory_fn+\".pkl\", \"wb\") as file:\n",
    "            pickle.dump(self.memory, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(\"MEMORY-N_\"+memory_fn+\".pkl\",\"wb\") as file:\n",
    "            pickle.dump(self.memory_n, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def test(self):\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        self.dqn.eval()\n",
    "        state = self.env.reset(seed = self.seed)\n",
    "        score = 0\n",
    "        original_len = [len(self.scores),len(self.portfolio),len(self.inventory)]\n",
    "        # step = 0\n",
    "        # while True:\n",
    "        test_progress = tqdm(range(14258), desc=\"Testing\", position=0, leave=True)\n",
    "        for step in test_progress:\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            self.scores.append(score*100)\n",
    "            \n",
    "            test_progress.set_postfix({\"Score\": score,\"Portfolio\":self.portfolio[-1],\"Inventory\":self.inventory[-1]})\n",
    "            # plotting\n",
    "            if (step+1) % 200 ==0:\n",
    "                self._plot(self.episode,n_score = 150, n_portfolio=14258)\n",
    "                if (step+1) % 1000 == 0:\n",
    "                    self._plot_all()\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset(seed = self.seed)\n",
    "                score = 0\n",
    "                self.scores = self.scores[:original_len[0]-1]\n",
    "                self.portfolio = self.portfolio[:original_len[1]-1]\n",
    "                self.inventory = self.inventory[:original_len[2]-1]\n",
    "                break\n",
    "        self.dqn.train()\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_action = self.dqn(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
    "\n",
    "        return elementwise_loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self,\n",
    "        episode: int,\n",
    "        n_score:int,\n",
    "        n_portfolio:int\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        if len(self.portfolio) < 14258:\n",
    "            n_portfolio = len(self.portfolio)\n",
    "\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(15, 10))  # Adjusted figure size\n",
    "        \n",
    "        if len(self.losses) > 0:\n",
    "            plt.subplot(221)  # Subplot 1\n",
    "            plt.title('episode %s. score: %s' % (episode, np.mean(self.scores[-10:])))\n",
    "            plt.plot(self.scores[-n_score:])\n",
    "            plt.subplot(222)  # Subplot 2\n",
    "            plt.title('loss')\n",
    "            plt.plot(self.losses[-n_score:])#\n",
    "        \n",
    "        plt.subplot(223)  # Subplot 3\n",
    "        plt.title('episode %s. portfolio: %s' % (episode, self.portfolio[-1]))\n",
    "        plt.plot(self.portfolio[-n_portfolio:])\n",
    "        \n",
    "        plt.subplot(224)  # Subplot 4\n",
    "        plt.title('episode %s. inventory: %s' % (episode, np.mean(self.inventory[-10:])))\n",
    "        plt.plot(self.inventory[-n_portfolio:])#\n",
    "        \n",
    "        plt.tight_layout()  # Adjust subplots to fit into the figure\n",
    "        plt.show()\n",
    "    def _plot_all(\n",
    "        self,\n",
    "    ):\n",
    "        self._plot(episode=1,n_score=len(self.scores),n_portfolio=len(self.portfolio))\n",
    "    def get_plot_data(self):\n",
    "        return self.scores, self.losses, self.portfolio, self.inventory\n",
    "    def clear_plot_history(self,ALL = False,n_score = 0, n_losses = 0, n_portfolio=0, n_inventory=0):\n",
    "        if ALL:\n",
    "            del self.scores\n",
    "            del self.losses\n",
    "            del self.portfolio\n",
    "            del self.inventory\n",
    "            return\n",
    "        self.scores = self.scores[n_score:]\n",
    "        self.losses = self.losses[n_losses:]\n",
    "        self.portfolio = self.portfolio[n_portfolio:]\n",
    "        self.inventory = self.inventory[n_inventory:]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = CustomEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2968686879\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "seed_torch(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = 10000\n",
    "memory_size = 10000\n",
    "batch_size = 128 #640\n",
    "target_update = 100 #500\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.Hyper_param(env,100,seed,lr=1,gamma=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/14258 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 174/14258 [00:16<1:05:38,  3.58it/s, loss=3.44, Portfolio=1.02e+3, Inventory=0.172]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3c6a32d3853e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mportfolio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minventory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b07e56a3a070>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mtrain_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14258\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_progress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b07e56a3a070>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# NoisyNet: no epsilon greedy action selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         selected_action = self.dqn(\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         ).argmax()\n\u001b[1;32m    172\u001b[0m         \u001b[0mselected_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-890a618a8528>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;34m\"\"\"Forward method implementation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-890a618a8528>\u001b[0m in \u001b[0;36mdist\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;34m\"\"\"Get distribution for atoms.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mConv_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvolution_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size, 42, 128]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "max_inventory: float = 1\n",
    "\n",
    "from datetime import datetime\n",
    "while i < 100:\n",
    "    i+=1\n",
    "    agent.train()\n",
    "    agent._plot_all()\n",
    "    scores, losses, portfolio, inventory = agent.get_plot_data()\n",
    "    if max(inventory) >= max_inventory:\n",
    "        max_inventory = max(inventory)\n",
    "        now = datetime.now()\n",
    "        timestamp = now.strftime(\"%d-%m-%Y-%H-%M\")\n",
    "        filename = \"CONV1_dropout20_agent_\"+str(timestamp)+\"max_inv=\"+str(max_inventory)+\".pkl\"\n",
    "        agent.save_model(filename=\"CONV1_dropout20_agent_\"+str(timestamp)+\"max_inv=\"+str(max_inventory)+\".pth\")\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(agent, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%d-%m-%Y-%H-%M\")\n",
    "filename = \"CONV1_agent_\"+str(timestamp)+\"max_inv=\"+str(max_inventory)+\".pkl\"\n",
    "agent.save_model(filename=\"CONV1_agent_\"+str(timestamp)+\"max_inv=\"+str(max_inventory)+\"min_loss=\"+min(losses)+\".pth\")\n",
    "# with open(filename, \"wb\") as file:\n",
    "#     pickle.dump(agent, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  27%|██▋       | 3840/14258 [00:32<01:49, 95.29it/s, Score=-.0269, Portfolio=1.54e+3, Inventory=0.132]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0917ea8acd5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-9ca3e1f39c08>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mtest_progress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14258\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Testing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_progress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9ca3e1f39c08>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# NoisyNet: no epsilon greedy action selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         selected_action = self.dqn(\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         ).argmax()\n\u001b[1;32m    133\u001b[0m         \u001b[0mselected_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0d6b063e0de1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m\"\"\"Forward method implementation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0d6b063e0de1>\u001b[0m in \u001b[0;36mdist\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mq_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madvantage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_atoms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for avoiding nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
       "        <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAHN5tZGF0AAACsAYF//+s3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MSByMzAzME0gOGJkNmQyOCAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMjAgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDM6MHgxMTMgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTEgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9LTIgdGhyZWFkcz0xMiBsb29rYWhlYWRfdGhyZWFkcz0yIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAG/ZYiEACf//vWxfApqyfOKDOgyLuGXJMmutiLibQDAFQ+wAAADAAATKpYnsyAlGpfAAAAQkANQH0GUHmImKsVAleIOBmriALkwL5pacv8ySayPhF43gb1plLBUL8CkRb1l2I8Dg58iWLxiO+miciASd2yvRbE4vMCvnJZXDcGubLgAnifLvrJzcMb0AvICCzDRe31/j4vhNAXDuz+ZDHOKuA99qAK72UvpyncE1w/9VE4E21ODwBg4bnuwcRZUIi7AvMmVUJ6b9hZ3v2DkvpV4Ak/fSTZZ5vIvSNJpnh4ifPOQsHz0AlfLzCzIuiUGPyxmLlDveEzscBOCbJ8VKVbjDCk81DHgEv+azP/NQPxeuZSwLyhRbceBerRk5bD+uaE90XCzRNOuwIybOMXF31efm17KqUhiunQtffSCGhqe/va8AF1CT3OAEcvC/PHoM/bYe0W2DWwqR+cgZxccZIzjuQP6ljItM/KfGQa0MU2ScDWRZUpoXoxiOfkX4KJgAEztUGjEWYmbytDRaH1R2uoWjQkHkaIqqanjV5Hj3zv53mhgeI1Tm2s466unAc/cDoo8JhlGohjgAAADAAADADAhAAAAT0GaJGxC//6MsAAAChew++jpLv4xVLLXyBkAuCHuTRUxkAbOqI4jVZZ57UCo2RqVHkC/uixkVwpThEskyW7BhYs7OU+XXDWFZL+cG1oxU6EAAAAiQZ5CeIR/AAADAzlzoXHKxzAP+vq28FwAcXs3LTrvHh4/owAAABMBnmF0R/8AAAMAQ1hyDRbQTTGwAAAAHQGeY2pH/wAABR801bGTC8/rwBUNX82ZDkA6O0qBAAAAQEGaaEmoQWiZTAhX//44QAAAJZxDexdZvZTABxGnBgSxbanpicxNClxQjbXb5n7eQUmvdXnQnKJcMUOrRtustX8AAAAhQZ6GRREsI/8AAAMDJTHNo7eWcSO9SznU2illN5A7UX+BAAAAEAGepXRH/wAAAwACOuqUtlEAAAAbAZ6nakf/AAAE+zTV3tuIaoJIG+jw6CRwkZOSAAAAZUGarEmoQWyZTAhP//3xAAADAPJM0gg5eAG5alsel20qwgeYfQCbG6VcN4BoGFvfPpY9EQINKEv6+6hW7dlxQKUXO3MiIveNtHxArgyOMhvrxlSIX2Inzho0c1J9Tjr+UlXjOi/gAAAAHUGeykUVLCP/AAADAzkwebbiuZVjqXVL0PjyanxxAAAADgGe6XRH/wAAAwAAAwGpAAAAGQGe62pH/wAADTSfl8cDTcVrTiSflMtfxQQAAAAuQZrwSahBbJlMCE///fEAAAMAX2UNIAcqtpYf1+qQKpoCmKegIIgrVH9p0SDxgQAAACRBnw5FFSwj/wAAAwM5MHm24rmVlp6knFIDYSn7+FEiAz2U58EAAAAfAZ8tdEf/AAANMtcLTOxBgjKB+DjzBKcRBQCWMnjbcQAAABwBny9qR/8AAAUfMJZ7iS0zXP3swSfB94AXQrZgAAAAPEGbNEmoQWyZTAhn//6eEAAARUUotAHC2wPBrQIOFqiQ+vS/A/8kDOAGoUiwkoc/u6yeeAi2LSpPzpxFlAAAACNBn1JFFSwj/wAAFrxDzbcWF7Xyymcj6KlX55X1jZSCsbTEBQAAAB4Bn3F0R/8AAA0OjhMdkqgVL4kTXY6sdkIjyFN5SoAAAAAcAZ9zakf/AAAjvwQnEslpmysEdURW9HmTypSOSAAAABdBm3hJqEFsmUwIZ//+nhAAAAMAAAMDPwAAABBBn5ZFFSwj/wAAAwAAAwEHAAAADgGftXRH/wAAAwAAAwGpAAAADgGft2pH/wAAAwAAAwGpAAAAF0GbvEmoQWyZTAhn//6eEAAAAwAAAwM+AAAAEEGf2kUVLCP/AAADAAADAQcAAAAOAZ/5dEf/AAADAAADAakAAAAOAZ/7akf/AAADAAADAakAAAAXQZvgSahBbJlMCGf//p4QAAADAAADAz8AAAAeQZ4eRRUsI/8AABazK7UFuRwqSyLhNEd9Kjg2woRsAAAAFwGePXRH/wAAI8MXaKmlU9T7wnbHENmAAAAAFwGeP2pH/wAAI78EJxLJaZq4XbkkUIOBAAAAF0GaJEmoQWyZTAhn//6eEAAAAwAAAwM+AAAAI0GeQkUVLCP/AAADAzdw+fSDNcGcyYNiP7MRsAW10yGA5u25AAAAGQGeYXRH/wAABR/Qwc8auO5s4hIlPix3fgwAAAAdAZ5jakf/AAADAeZ/1Wxfuw3fSfDCP+U2oWi47cEAAAAXQZpoSahBbJlMCGf//p4QAAADAAADAz8AAAAQQZ6GRRUsI/8AAAMAAAMBBwAAAA4BnqV0R/8AAAMAAAMBqQAAAA4BnqdqR/8AAAMAAAMBqQAAACFBmqxJqEFsmUwIZ//+nhAAAAMAAsfVIQQII4U6TCph6rYAAAAQQZ7KRRUsI/8AAAMAAAMBBwAAAA4Bnul0R/8AAAMAAAMBqQAAAA4BnutqR/8AAAMAAAMBqQAAABdBmvBJqEFsmUwIX//+jLAAAAMAAAMDQwAAAB5Bnw5FFSwj/wAAFrMrtQW5HCpLIuE0R30qODbChG0AAAAXAZ8tdEf/AAAjwxdoqaVT1PvCdscQ2YEAAAAXAZ8vakf/AAAjvwQnEslpmrhduSRQg4AAAABUQZs0SahBbJlMCF///oywAAAKCtq9R+ugBxc4OHiR4lQ9IHtR+oPCmtf2K0qzhKrNvY2OBY/Hq7rcoGkRLE85kVHiQYKgDB0a7f1JfKvc1+YbvwHsAAAAHUGfUkUVLCP/AAADATWBSGNfAgwBz0qSnDBN/HgxAAAAGwGfcXRH/wAAAwHlih4h09hDuxrSPKtEVTj+DAAAABABn3NqR/8AAAMAtfaAygRcAAAAGkGbeEmoQWyZTAhf//6MsAAAAwFlBnRvoB/hAAAAK0GflkUVLCP/AAAWsyu1Bbkc50ObZgv914XI/7RDm7aG+C24IwQWQyXOckAAAAAcAZ+1dEf/AAAjwxdoqaVT1PyDVNJhAEKwMHOSTQAAAB0Bn7dqR/8AACO/BCcSyWmauF24luk52QXQqeQdswAAABZBm7xJqEFsmUwIV//+OEAAAAMAAAyoAAAAIUGf2kUVLCP/AAAWwJs/Yf2GQchFaN4zaxATTofmUMPskwAAABwBn/l0R/8AACPDF2ippVPU+8IJjrAYLdbrsEBAAAAAHQGf+2pH/wAAI78EJxLJaZq4XbApiqbaLg+VM/gxAAAAF0Gb4EmoQWyZTAhP//3xAAADAAADAB6RAAAAIUGeHkUVLCP/AAAWwJs/Yf2GQchFaN3CpH6a/Dw+nUUkmAAAABwBnj10R/8AACPDF2ippVPU+8IJjrAYLdbrsEBAAAAAHQGeP2pH/wAAI78EJxLJaZq4XbApiqbaLg+VM/gxAAAANkGaJEmoQWyZTAhn//6eEAAARVH19XC+EEAEZwlx77PlY+/rKHhvwwqMGKy2sSSA6UM+w7Fj5gAAACNBnkJFFSwj/wAAFrUrN2tasvjmI2xPBSxYaxvR6hsNIaD23QAAABwBnmF0R/8AACPDF2ippVPU+8IJjrAYLdbrsEBAAAAAGgGeY2pH/wAAAwC6ZhLPcSWm3umfHpIG8C2zAAAAF0GaaEmoQWyZTAhf//6MsAAAAwAAAwNDAAAAEEGehkUVLCP/AAADAAADAQcAAAAOAZ6ldEf/AAADAAADAakAAAAOAZ6nakf/AAADAAADAakAAABMQZqsSahBbJlMCF///oywAAAJv7haLQEtxyAAcOamLch4P93597zcK2K73XmU4mPkqszIsaE5CzLqyhA8OLRFlwp3OwSH3iJUrVBlgAAAAB9BnspFFSwj/wAAAwMlMc2jt5ZxI71LOdTaKVtHTEBBAAAADgGe6XRH/wAAAwAAAwGpAAAAGwGe62pH/wAABPs01d7biGqCSBvo8OgkcJGTkgAAABZBmvBJqEFsmUwIV//+OEAAAAMAAAypAAAAIEGfDkUVLCP/AAADAyW77JiDfHzOYxoYiK0k4Z38OIgJAAAAGwGfLXRH/wAAAwHbsiYf2amkATxT9v/HgVE5IQAAABsBny9qR/8AAAT7NNXe24hqgkgb6PDoJHCRk5IAAAAXQZs0SahBbJlMCE///fEAAAMAAAMAHpAAAAAgQZ9SRRUsI/8AAAMDJbvsmIN8fM5jGhiIrSThnfw4iAkAAAAbAZ9xdEf/AAADAduyJh/ZqaQBPFP2/8eBUTkgAAAAGwGfc2pH/wAABPs01d7biGqCSBvo8OgkcJGTkgAAAHlBm3hJqEFsmUwIT//98QAAAwBc+UuG3zfJxtCAC58brTMFC1gpsoFUG+XZ9YT8XHTguJN/McahE+t+JiPWfcU4jZm2qvT/m0oF1XjkmnMAWvAZg82LYIpCbcSTI/CPJiu2g04xLV6yG6hg7id9VqRSn6kgQ6DvtMvhAAAAIUGflkUVLCP/AAADAyRT6YuwN+t0ztfGsDARq2MlD3fwYAAAABsBn7V0R/8AAAMB2yYcc0wrNIowRk3XW85LTkkAAAAYAZ+3akf/AAADAeZ+lsnylpmrhWUySBgxAAAAJUGbvEmoQWyZTAhn//6eEAAAAwO0gN9XC96Xmx7fDyyBS44MY+AAAAAZQZ/aRRUsI/8AAAMBNX9c43ml64ooPOUr4QAAACEBn/l0R/8AAAUakmGTym4E4VRvICdlfCZAxg3tqlb7lswAAAAOAZ/7akf/AAADAAADAakAAAAXQZvgSahBbJlMCGf//p4QAAADAAADAz8AAAAQQZ4eRRUsI/8AAAMAAAMBBwAAAA4Bnj10R/8AAAMAAAMBqQAAAA4Bnj9qR/8AAAMAAAMBqQAAABdBmiRJqEFsmUwIZ//+nhAAAAMAAAMDPgAAABBBnkJFFSwj/wAAAwAAAwEHAAAADgGeYXRH/wAAAwAAAwGpAAAADgGeY2pH/wAAAwAAAwGpAAAAF0GaaEmoQWyZTAhn//6eEAAAAwAAAwM/AAAAEEGehkUVLCP/AAADAAADAQcAAAAOAZ6ldEf/AAADAAADAakAAAAOAZ6nakf/AAADAAADAakAAAAXQZqsSahBbJlMCF///oywAAADAAADA0IAAAAQQZ7KRRUsI/8AAAMAAAMBBwAAAA4Bnul0R/8AAAMAAAMBqQAAAA4BnutqR/8AAAMAAAMBqQAAABdBmvBJqEFsmUwIX//+jLAAAAMAAAMDQwAAADFBnw5FFSwj/wAAAwM2g/YGzlKo2nnbIAFraMQtlT7kRiJ/luWqu6LbX9LZyF1X27ZhAAAAGgGfLXRH/wAABR/Qwc62jcNX2BFaCJxmV2zBAAAAHAGfL2pH/wAAAwHmf9VOUbCGGzlaK4C4oo/Z9swAAAAWQZs0SahBbJlMCFf//jhAAAADAAAMqAAAACJBn1JFFSwj/wAAAwM5u+yWFlll0YEM0vhUL/3xZraNL2zBAAAAGgGfcXRH/wAABR/Qwc62jcNX2BFaCJxmV2zAAAAAHAGfc2pH/wAAAwHmf9VOUbBQHgBs9tGxgzz/tmAAAAAXQZt4SahBbJlMCE///fEAAAMAAAMAHpEAAAAgQZ+WRRUsI/8AAAMDObvslhZZZdOlDN+Iwna1u8nPbbgAAAAaAZ+1dEf/AAAFH9DBzraNw1fYEVoInGZXbMEAAAAbAZ+3akf/AAADAeZ/1Ul/E3HV9ncYh4anJjtxAAAAO0GbvEmoQWyZTAhX//44QAABDaKPl1Ub0MwwyVf9Uj9ADctdrzznQNDbDVID/eWTlanVCtlDD6Vx8KQ8AAAAIUGf2kUVLCP/AAAWvEPNtxYX2Q96IRUC8ElkVhRXKcYTkwAAABoBn/l0R/8AAAUf0MHOto3DV9gRWgicZldswAAAAB0Bn/tqR/8AACO/BCcSyWmauFZTHyo7fi+tjQSSYQAAABpBm+BJqEFsmUwIT//98QAAAwANg6EfRGATMQAAABJBnh5FFSwj/wAAAwB0AHIAh4AAAAAQAZ49dEf/AAADALoLfsCrgAAAAA4Bnj9qR/8AAAMAAAMBqQAAAEFBmiRJqEFsmUwIZ//+nhAAAAm3v42SVj/M7Q5QgU9j8Wayeb1WhtGVZyiNqOS5WEOIAaan8TmtQMrwk0JyGZ9BYAAAADhBnkJFFSwj/wAAFrNHtw25OEABqxNbADUtNQpecba8Gh2FBs35E40O/afIHavgFjxd8UhVqjaPBwAAAB8BnmF0R/8AACPDF2ippcMOtYMF5GGKYtIXCtkDoWzAAAAAGAGeY2pH/wAAI78EJxLJaZq4VnMEXInHTQAAABdBmmhJqEFsmUwIZ//+nhAAAAMAAAMDPwAAACFBnoZFFSwj/wAAAwMlfNK7fAcoSK0vHSQX8jKm5aFXJMEAAAAaAZ6ldEf/AAAE+9DCGG1xHpuevXktHmaWEgMAAAAcAZ6nakf/AAADAduAEvjgabitdUKXCTtmVuDkgAAAABdBmqxJqEFsmUwIZ//+nhAAAAMAAAMDPgAAACBBnspFFSwj/wAAAwMlu+yYg3x8zmMaGIitJOGd/DiICQAAABoBnul0R/8AAAT70MIYbXEem569eS0eZpYSAgAAABwBnutqR/8AAAMB24AS+OBpuK11QpcJO2ZW4OSAAAAAF0Ga8EmoQWyZTAhn//6eEAAAAwAAAwM/AAAAIEGfDkUVLCP/AAADAyW77JiDfHzOYxoYiK0k4Z38OIgJAAAAGgGfLXRH/wAABPvQwhhtcR6bnr15LR5mlhIDAAAAHAGfL2pH/wAAAwHbgBL44Gm4rXVClwk7Zlbg5IAAAAAXQZs0SahBbJlMCGf//p4QAAADAAADAz4AAAAQQZ9SRRUsI/8AAAMAAAMBBwAAAA4Bn3F0R/8AAAMAAAMBqQAAAA4Bn3NqR/8AAAMAAAMBqQAAABdBm3hJqEFsmUwIZ//+nhAAAAMAAAMDPwAAABBBn5ZFFSwj/wAAAwAAAwEHAAAADgGftXRH/wAAAwAAAwGpAAAADgGft2pH/wAAAwAAAwGpAAAAF0GbvEmoQWyZTAhn//6eEAAAAwAAAwM+AAAAEEGf2kUVLCP/AAADAAADAQcAAAAOAZ/5dEf/AAADAAADAakAAAAOAZ/7akf/AAADAAADAakAAAAXQZvgSahBbJlMCF///oywAAADAAADA0MAAAAQQZ4eRRUsI/8AAAMAAAMBBwAAAA4Bnj10R/8AAAMAAAMBqQAAAA4Bnj9qR/8AAAMAAAMBqQAAABdBmiRJqEFsmUwIX//+jLAAAAMAAAMDQgAAABBBnkJFFSwj/wAAAwAAAwEHAAAADgGeYXRH/wAAAwAAAwGpAAAADgGeY2pH/wAAAwAAAwGpAAAAIEGaaEmoQWyZTAhf//6MsAAAAwFtxUEAcNx0+50KEl4RAAAAEEGehkUVLCP/AAADAAADAQcAAAAOAZ6ldEf/AAADAAADAakAAAAOAZ6nakf/AAADAAADAakAAABPQZqsSahBbJlMCFf//jhAAAAmr/jFn2RACsUm7+D6raqbedh+7x7t/zbmBDpprodqZhvnQqYrx01tU9bAI+FfuK8ePUm7hdeehtNlpqJJQAAAAB5BnspFFSwj/wAAAwM4Uji0Xjm85Bvts+Ph9V3flt0AAAAaAZ7pdEf/AAAFH9DBzraNw1fYEVoInGZXbMAAAAAQAZ7rakf/AAADALX2gMoEXAAAABlBmvBJqEFsmUwIT//98QAAAwANLQ+s9gIXAAAAOUGfDkUVLCP/AAAWsyu1BbkZ455yFe3OllGj/3c1UgBscUeNGl/kzogOrrooA1wigIvVO3mQkU6sGQAAAB0Bny10R/8AACPDF2ippVPBIBAH4+bR/MPEKWBCAwAAAB0Bny9qR/8AACO/BCcSyWmauFZTHyo7fi+tjQSSYAAAADJBmzRJqEFsmUwIZ//+nhAAAEVR9gTQCN/VFWLqNYZ0oj49AV2gEayktGxsBi2xtrQ0IAAAACFBn1JFFSwj/wAAFrUrN2tasvjmI2xQqPCkMWC/CpBz228AAAAeAZ9xdEf/AAAjwxdoqaVTwSALcv7aeV/3jdChng5IAAAAGwGfc2pH/wAAAwC15rl8cDTdEGzOMBFVLpbbgAAAABdBm3hJqEFsmUwIX//+jLAAAAMAAAMDQwAAACFBn5ZFFSwj/wAAAwMjrnllo765NLBKkadG5/J+iP6aNbMAAAAaAZ+1dEf/AAAE+9DCGG1xHpuevXktHmaWEgMAAAAbAZ+3akf/AAADAdt/1Xe24hqhRFvovP42CetnAAAAF0GbvEmoQWyZTAhf//6MsAAAAwAAAwNCAAAAIEGf2kUVLCP/AAADAyOulDfvrW1KitZJHndwj5KWtpEBAAAAGgGf+XRH/wAABPvQwhhtcR6bnr15LR5mlhICAAAAGwGf+2pH/wAAAwHbf9V3tuIaoURb6Lz+NgnrZwAAABdBm+BJqEFsmUwIX//+jLAAAAMAAAMDQwAAADtBnh5FFSwj/wAAAwM2aGt4WtCkPQKiIgCI7jWPT6wV6WANPWGDin+029OaZZMzIEGj2R7FF/qtnx1QQAAAABYBnj10R/8AAAUf0MHOto3DV288KiYOAAAAIAGeP2pH/wAAAwHmf9VOUbBQHgCA7oA2m54DgjpOJNtvAAAAFkGaJEmoQWyZTAhX//44QAAAAwAADKgAAAAQQZ5CRRUsI/8AAAMAAAMBBwAAAA4BnmF0R/8AAAMAAAMBqQAAAA4BnmNqR/8AAAMAAAMBqQAAABdBmmhJqEFsmUwIR//94QAAAwAAAwAxYQAAABBBnoZFFSwj/wAAAwAAAwEHAAAADgGepXRH/wAAAwAAAwGpAAAADgGep2pH/wAAAwAAAwGpAAAAFkGaqUmoQWyZTAj//IQAAAMAAAMAwIAAAAyjbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAD8gAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAC810cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAD8gAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAlgAAAGQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAA/IAAACAAABAAAAAAtFbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAAAygBVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAK8G1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACrBzdGJsAAAAsHN0c2QAAAAAAAAAAQAAAKBhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAlgBkABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAANmF2Y0MBZAAf/+EAGWdkAB+s2UCYM+XhAAADAAEAAAMAZA8YMZYBAAZo6+PLIsD9+PgAAAAAFGJ0cnQAAAAAAAA5GQAAORkAAAAYc3R0cwAAAAAAAAABAAAAygAAAQAAAAAUc3RzcwAAAAAAAAABAAAAAQAABmBjdHRzAAAAAAAAAMoAAAABAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABHcAAABTAAAAJgAAABcAAAAhAAAARAAAACUAAAAUAAAAHwAAAGkAAAAhAAAAEgAAAB0AAAAyAAAAKAAAACMAAAAgAAAAQAAAACcAAAAiAAAAIAAAABsAAAAUAAAAEgAAABIAAAAbAAAAFAAAABIAAAASAAAAGwAAACIAAAAbAAAAGwAAABsAAAAnAAAAHQAAACEAAAAbAAAAFAAAABIAAAASAAAAJQAAABQAAAASAAAAEgAAABsAAAAiAAAAGwAAABsAAABYAAAAIQAAAB8AAAAUAAAAHgAAAC8AAAAgAAAAIQAAABoAAAAlAAAAIAAAACEAAAAbAAAAJQAAACAAAAAhAAAAOgAAACcAAAAgAAAAHgAAABsAAAAUAAAAEgAAABIAAABQAAAAIwAAABIAAAAfAAAAGgAAACQAAAAfAAAAHwAAABsAAAAkAAAAHwAAAB8AAAB9AAAAJQAAAB8AAAAcAAAAKQAAAB0AAAAlAAAAEgAAABsAAAAUAAAAEgAAABIAAAAbAAAAFAAAABIAAAASAAAAGwAAABQAAAASAAAAEgAAABsAAAAUAAAAEgAAABIAAAAbAAAANQAAAB4AAAAgAAAAGgAAACYAAAAeAAAAIAAAABsAAAAkAAAAHgAAAB8AAAA/AAAAJQAAAB4AAAAhAAAAHgAAABYAAAAUAAAAEgAAAEUAAAA8AAAAIwAAABwAAAAbAAAAJQAAAB4AAAAgAAAAGwAAACQAAAAeAAAAIAAAABsAAAAkAAAAHgAAACAAAAAbAAAAFAAAABIAAAASAAAAGwAAABQAAAASAAAAEgAAABsAAAAUAAAAEgAAABIAAAAbAAAAFAAAABIAAAASAAAAGwAAABQAAAASAAAAEgAAACQAAAAUAAAAEgAAABIAAABTAAAAIgAAAB4AAAAUAAAAHQAAAD0AAAAhAAAAIQAAADYAAAAlAAAAIgAAAB8AAAAbAAAAJQAAAB4AAAAfAAAAGwAAACQAAAAeAAAAHwAAABsAAAA/AAAAGgAAACQAAAAaAAAAFAAAABIAAAASAAAAGwAAABQAAAASAAAAEgAAABoAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguNzYuMTAw\" type=\"video/mp4\"/>\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played: videos/rainbow/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def ipython_show_video(path: str) -> None:\n",
    "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        raise NameError(\"Cannot access: {}\".format(path))\n",
    "\n",
    "    video = io.open(path, \"r+b\").read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display(HTML(\n",
    "        data=\"\"\"\n",
    "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode(\"ascii\"))\n",
    "    ))\n",
    "\n",
    "\n",
    "def show_latest_video(video_folder: str) -> str:\n",
    "    \"\"\"Show the most recently recorded video from video folder.\"\"\"\n",
    "    list_of_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    ipython_show_video(latest_file)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "latest_file = show_latest_video(video_folder=video_folder)\n",
    "print(\"Played:\", latest_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
